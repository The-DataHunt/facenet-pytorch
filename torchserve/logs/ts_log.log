2020-10-20 02:00:19,319 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:00:19,326 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet
2020-10-20 02:00:19,330 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: facenet
org.pytorch.serve.archive.ModelNotFoundException: Model not found in model store: facenet
	at org.pytorch.serve.archive.ModelArchive.downloadModel(ModelArchive.java:74)
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:137)
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:115)
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:213)
	at org.pytorch.serve.ModelServer.start(ModelServer.java:308)
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:104)
	at org.pytorch.serve.ModelServer.main(ModelServer.java:85)
2020-10-20 02:00:19,335 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:00:19,426 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:00:19,426 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:00:19,428 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:00:19,428 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:00:19,431 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:02:25,592 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:02:25,595 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:02:25,594 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:02:27,615 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:02:33,011 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: logs/config/20201020020225594-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:02:33,017 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20201020020225594-shutdown.cfg",
  "modelCount": 0,
  "created": 1603159345594,
  "models": {}
}
2020-10-20 02:02:33,026 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20201020020225594-shutdown.cfg
2020-10-20 02:02:33,028 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20201020020225594-shutdown.cfg validated successfully
2020-10-20 02:02:33,028 [WARN ] main org.pytorch.serve.snapshot.SnapshotManager - Model snapshot is empty. Starting TorchServe without initial models.
2020-10-20 02:02:33,031 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:02:33,124 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:02:33,125 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:02:33,133 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:02:33,133 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:02:33,135 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:06:03,011 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:06:03,012 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:06:03,014 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:06:05,036 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:06:11,940 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: logs/config/20201020020603013-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:06:11,946 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20201020020603013-shutdown.cfg",
  "modelCount": 0,
  "created": 1603159563013,
  "models": {}
}
2020-10-20 02:06:11,956 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20201020020603013-shutdown.cfg
2020-10-20 02:06:11,957 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20201020020603013-shutdown.cfg validated successfully
2020-10-20 02:06:11,958 [WARN ] main org.pytorch.serve.snapshot.SnapshotManager - Model snapshot is empty. Starting TorchServe without initial models.
2020-10-20 02:06:11,961 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:06:12,060 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:06:12,060 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:06:12,063 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:06:12,063 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:06:12,065 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:10:06,916 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:10:06,916 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:10:06,918 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:10:08,938 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:10:11,335 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:10:11,376 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet
2020-10-20 02:10:11,380 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: facenet
org.pytorch.serve.archive.ModelNotFoundException: Model not found in model store: facenet
	at org.pytorch.serve.archive.ModelArchive.downloadModel(ModelArchive.java:74)
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:137)
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:115)
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:213)
	at org.pytorch.serve.ModelServer.start(ModelServer.java:308)
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:104)
	at org.pytorch.serve.ModelServer.main(ModelServer.java:85)
2020-10-20 02:10:11,384 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:10:11,481 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:10:11,482 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:10:11,483 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:10:11,485 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:10:11,486 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:11:52,426 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:11:52,426 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:11:52,429 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:11:54,445 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:12:02,717 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:12:02,760 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet
2020-10-20 02:12:02,763 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: facenet
org.pytorch.serve.archive.ModelNotFoundException: Model not found in model store: facenet
	at org.pytorch.serve.archive.ModelArchive.downloadModel(ModelArchive.java:74)
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:137)
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:115)
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:213)
	at org.pytorch.serve.ModelServer.start(ModelServer.java:308)
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:104)
	at org.pytorch.serve.ModelServer.main(ModelServer.java:85)
2020-10-20 02:12:02,768 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:12:02,861 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:12:02,861 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:12:02,864 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:12:02,869 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:12:02,875 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:13:22,550 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:13:22,551 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:13:22,556 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:13:24,584 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:14:06,796 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:14:06,835 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet
2020-10-20 02:14:06,840 [WARN ] main org.pytorch.serve.ModelServer - Failed to load model: facenet
org.pytorch.serve.archive.ModelNotFoundException: Model not found in model store: facenet
	at org.pytorch.serve.archive.ModelArchive.downloadModel(ModelArchive.java:74)
	at org.pytorch.serve.wlm.ModelManager.createModelArchive(ModelManager.java:137)
	at org.pytorch.serve.wlm.ModelManager.registerModel(ModelManager.java:115)
	at org.pytorch.serve.ModelServer.initModelStore(ModelServer.java:213)
	at org.pytorch.serve.ModelServer.start(ModelServer.java:308)
	at org.pytorch.serve.ModelServer.startAndWait(ModelServer.java:104)
	at org.pytorch.serve.ModelServer.main(ModelServer.java:85)
2020-10-20 02:14:06,845 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:14:06,936 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:14:06,936 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:14:06,937 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:14:06,938 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:14:06,939 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:17:26,407 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:17:26,406 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:17:26,413 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:17:28,441 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:17:32,258 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:17:32,299 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 02:17:32,395 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 9bf422feda0a4b74a6f0ef313d9ae8e3
2020-10-20 02:17:32,409 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 02:17:32,409 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 02:17:32,409 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 02:17:32,410 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 02:17:32,431 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:17:32,601 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:17:32,611 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:17:32,611 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:17:32,619 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]439
2020-10-20 02:17:32,619 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:32,620 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:17:32,620 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]441
2020-10-20 02:17:32,623 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:32,621 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:32,626 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:32,621 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]442
2020-10-20 02:17:32,623 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:17:32,627 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:32,627 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:32,627 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:17:32,635 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:17:32,632 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:17:32,637 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:17:32,635 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:17:32,641 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]440
2020-10-20 02:17:32,642 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:32,642 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:17:32,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:32,643 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:17:32,719 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:17:32,720 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:17:32,724 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:17:32,726 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:17:32,731 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:17:32,732 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:17:32,732 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:17:32,738 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:17:32,740 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:17:33,936 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:33,936 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:33,936 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:33,937 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:33,938 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:33,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:33,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:33,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:33,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:33,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:33,942 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:33,942 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:33,943 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:33,943 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:33,944 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:33,944 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:33,945 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:33,945 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:33,946 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:33,946 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:33,947 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:33,947 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:33,947 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:33,947 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:33,947 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:33,948 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:33,948 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:33,947 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:33,975 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:33,974 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:33,976 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:33,963 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:33,949 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:33,977 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:33,977 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:33,978 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:33,978 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:33,978 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:33,980 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:33,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:33,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:33,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:33,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:33,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:33,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:33,983 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:33,983 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:33,983 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:33,983 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:33,983 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:33,983 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:33,984 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:33,984 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:17:33,984 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:33,984 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:33,984 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:33,984 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:33,985 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:33,985 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:33,986 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:33,986 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:33,986 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:33,986 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:33,986 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:33,986 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:33,984 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:33,984 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:17:33,987 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:33,987 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:33,988 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:17:33,988 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2020-10-20 02:17:33,988 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:33,989 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:33,987 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:33,989 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:33,989 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:33,989 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:33,989 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:33,990 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:33,990 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:33,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:17:33,990 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:33,991 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:33,991 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:33,991 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:33,991 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:33,992 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:33,993 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:17:33,987 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:17:33,999 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:17:33,999 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2020-10-20 02:17:33,998 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:33,999 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:17:33,998 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:17:33,990 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:17:34,000 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2020-10-20 02:17:34,002 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:17:34,005 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:17:34,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:34,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:34,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:34,011 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:34,011 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:34,011 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:34,011 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:34,012 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:34,012 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:34,012 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:34,012 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:34,013 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:17:34,013 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:17:34,013 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2020-10-20 02:17:34,012 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:34,013 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:17:34,020 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:17:35,099 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:17:35,103 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]499
2020-10-20 02:17:35,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:35,105 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:35,105 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:17:35,109 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:35,113 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:17:35,117 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:17:35,117 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]504
2020-10-20 02:17:35,118 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:35,118 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:35,118 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:17:35,119 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:35,124 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:17:35,125 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]502
2020-10-20 02:17:35,125 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:35,125 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:35,125 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:35,125 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:17:35,133 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:17:35,135 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]508
2020-10-20 02:17:35,136 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:35,136 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:35,136 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:17:35,137 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:35,137 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:17:35,144 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:17:35,147 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:17:36,205 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:36,206 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:36,207 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:36,208 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,209 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,210 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,210 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,210 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:36,210 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:36,211 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,212 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:36,213 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:36,213 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:36,213 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:36,213 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:36,213 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:36,213 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:36,214 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:36,214 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:36,214 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:36,214 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:36,214 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,215 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:36,215 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,215 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,215 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:36,215 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:36,215 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:36,216 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:36,216 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:36,216 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:36,217 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:17:36,217 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:17:36,217 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2020-10-20 02:17:36,217 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:36,217 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,218 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:36,218 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:36,218 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,218 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,218 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,218 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,219 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:36,219 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:36,219 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:36,219 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:36,219 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:36,219 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:36,220 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:36,220 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:36,221 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:36,221 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:36,221 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:36,221 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:36,221 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:36,222 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,221 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:36,222 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:36,222 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:36,222 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,222 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,223 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:36,223 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:36,223 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:36,223 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:36,223 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:36,223 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:36,223 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:36,224 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:36,224 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:36,224 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:36,224 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:36,225 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:36,225 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,225 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,226 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,226 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,226 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:36,226 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:36,227 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:36,227 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:36,227 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:36,227 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:36,227 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,228 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,228 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,228 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,228 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:36,228 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:36,229 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:36,243 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:36,235 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:17:36,235 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:17:36,230 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:36,244 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:36,244 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:36,244 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:36,244 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:17:36,244 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:36,245 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:17:36,245 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2020-10-20 02:17:36,246 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:36,246 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:36,247 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:17:36,247 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:17:36,247 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,251 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,252 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,252 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:17:36,252 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:17:36,252 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:36,256 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:36,256 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:36,256 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:36,256 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:36,256 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:36,256 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:36,256 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:36,257 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:36,257 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:36,257 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:36,257 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:36,264 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:17:36,265 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:36,265 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:36,265 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:17:36,265 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:17:36,265 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:36,266 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:36,267 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:36,267 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:36,267 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:36,267 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:36,267 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:36,267 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:36,268 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:36,268 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:36,268 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:36,268 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:36,269 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:36,269 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:36,269 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:36,269 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:36,269 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:17:36,270 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2020-10-20 02:17:36,272 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:17:37,321 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:17:37,321 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]523
2020-10-20 02:17:37,322 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:37,322 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:37,322 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:17:37,322 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:37,325 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:17:37,359 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:17:37,361 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]526
2020-10-20 02:17:37,362 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:37,362 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:37,363 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:17:37,364 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:37,365 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:17:37,374 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:17:37,374 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]528
2020-10-20 02:17:37,375 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:37,375 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:37,376 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:37,377 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:17:37,380 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:17:37,398 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:17:37,398 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]532
2020-10-20 02:17:37,399 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:37,399 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:37,399 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:17:37,400 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:37,403 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:17:38,400 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:38,400 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,401 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:38,401 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:38,401 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,401 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,402 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,402 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,404 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:38,404 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:38,404 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:38,404 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:38,405 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:38,405 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:38,405 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:38,405 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:38,405 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,406 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:38,407 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:38,407 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:38,407 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:38,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:38,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:38,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:38,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:38,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:38,409 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:38,410 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,410 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,410 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,410 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,411 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:38,411 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:38,413 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:38,413 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:38,413 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:38,414 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:38,414 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:38,414 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:17:38,414 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:17:38,414 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2020-10-20 02:17:38,426 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:17:38,426 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:38,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:38,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,447 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,448 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:38,449 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:38,449 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,449 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:38,450 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,451 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:38,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:38,452 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:38,452 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:38,455 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:38,455 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:38,456 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:38,456 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:38,456 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:17:38,456 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:17:38,456 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2020-10-20 02:17:38,460 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:38,462 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:38,463 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:17:38,463 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:17:38,464 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:38,467 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:38,467 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:38,468 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:17:38,468 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:17:38,468 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:38,469 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:38,470 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:38,471 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:38,474 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:38,476 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:38,477 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:38,478 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:38,478 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:38,478 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:17:38,478 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:17:38,479 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2020-10-20 02:17:38,481 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:17:38,481 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:17:38,486 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:17:38,486 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:17:40,512 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:17:40,514 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]553
2020-10-20 02:17:40,516 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:40,516 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:40,516 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:17:40,518 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:40,519 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:17:40,574 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:17:40,575 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]556
2020-10-20 02:17:40,575 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:40,575 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:40,575 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:17:40,575 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:40,577 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:17:40,590 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:17:40,591 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]559
2020-10-20 02:17:40,591 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:40,591 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:40,591 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:17:40,592 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:40,594 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:17:40,605 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:17:40,606 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]562
2020-10-20 02:17:40,606 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:40,606 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:40,607 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:17:40,619 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:40,620 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:17:41,600 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:41,600 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,600 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:41,600 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:41,601 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:41,602 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,603 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,604 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,604 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,604 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:41,604 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:41,621 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:41,623 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:41,631 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:41,632 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:41,632 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:41,632 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:17:41,632 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:17:41,632 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2020-10-20 02:17:41,649 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:41,649 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,649 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:41,649 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:41,649 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,649 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:17:41,649 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:41,650 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:41,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,652 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,653 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:41,653 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:41,653 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:17:41,655 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:41,658 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:41,658 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:41,658 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:41,658 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:41,659 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:17:41,659 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:17:41,659 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2020-10-20 02:17:41,665 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:17:41,666 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:17:41,669 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:41,670 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,670 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:41,670 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:41,670 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:41,670 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,670 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,671 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,671 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,671 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:41,671 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:41,671 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:41,671 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:41,672 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:41,672 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:41,672 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:41,672 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:41,673 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:41,673 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:41,673 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:41,673 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:41,673 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:41,673 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:41,674 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,674 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:41,674 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:41,674 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:41,674 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:41,675 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:41,675 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:41,675 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:41,675 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:41,675 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:41,676 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:41,677 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:41,677 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:41,678 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:41,678 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:41,678 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:17:41,678 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:17:41,678 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2020-10-20 02:17:41,685 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:17:41,685 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:17:41,695 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:41,695 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:41,696 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:41,696 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:41,697 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:41,697 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:41,698 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:41,698 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:41,700 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:41,700 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:41,700 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:41,701 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:17:41,701 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:17:41,701 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2020-10-20 02:17:41,701 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:17:41,705 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:17:44,737 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:17:44,739 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]582
2020-10-20 02:17:44,740 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:44,741 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:44,741 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:17:44,741 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:44,747 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:17:44,781 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:17:44,783 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]585
2020-10-20 02:17:44,784 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:44,784 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:44,785 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:17:44,786 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:44,787 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:17:44,802 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:17:44,805 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]588
2020-10-20 02:17:44,806 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:44,806 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:44,807 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:17:44,811 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:44,812 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:17:44,838 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:17:44,838 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]591
2020-10-20 02:17:44,839 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:44,839 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:44,839 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:17:44,839 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:44,841 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:45,829 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:45,830 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:45,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:45,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:45,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:45,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:45,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:45,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:45,832 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:45,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:45,835 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:45,835 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:45,835 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:45,835 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:45,836 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:45,836 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:17:45,836 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:17:45,836 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2020-10-20 02:17:45,843 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:17:45,843 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:45,847 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:45,848 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:45,849 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:45,853 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:45,855 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:45,855 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:45,855 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:45,856 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:45,856 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:17:45,856 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:17:45,856 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2020-10-20 02:17:45,862 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:17:45,862 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:17:45,872 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:45,872 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,873 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:45,873 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:45,873 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:45,873 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:45,873 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:45,873 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:45,873 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:45,873 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:45,873 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:45,874 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:45,874 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:45,874 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:17:45,874 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:45,874 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:17:45,874 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:45,874 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2020-10-20 02:17:45,874 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:17:45,879 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:45,901 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:45,902 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:45,902 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:45,902 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:45,902 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:45,902 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:45,902 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:45,902 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:45,903 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:45,903 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:45,904 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:45,904 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:45,905 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:17:45,905 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:17:45,905 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2020-10-20 02:17:45,903 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:45,905 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:17:45,909 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:17:50,940 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:17:50,941 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]611
2020-10-20 02:17:50,941 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:50,941 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:50,941 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:17:50,941 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:50,942 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:17:50,959 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:17:50,961 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]614
2020-10-20 02:17:50,962 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:50,962 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:50,962 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:17:50,965 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:50,967 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:17:50,995 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:17:50,996 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]617
2020-10-20 02:17:50,996 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:50,996 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:50,996 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:50,996 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:17:50,997 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:17:51,036 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:17:51,037 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]620
2020-10-20 02:17:51,037 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:17:51,037 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:17:51,038 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:17:51,038 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:17:51,039 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:52,024 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:52,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:52,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:52,030 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:52,030 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:52,030 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:52,030 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:52,031 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:52,031 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:17:52,031 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:17:52,031 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2020-10-20 02:17:52,033 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:52,034 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:52,035 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:52,036 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:52,037 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:52,037 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:52,037 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:52,040 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:52,042 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:52,042 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:17:52,042 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:17:52,042 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:17:52,042 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:17:52,042 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2020-10-20 02:17:52,049 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:17:52,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:17:52,065 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:52,065 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,065 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:52,065 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:52,066 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,066 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:52,066 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,067 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:52,067 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,067 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,067 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:52,068 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:52,069 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:52,070 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:52,070 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:52,071 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:17:52,071 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:17:52,071 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2020-10-20 02:17:52,072 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:17:52,076 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:17:52,105 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:17:52,106 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:17:52,107 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:17:52,107 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:17:52,107 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:17:52,108 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:17:52,108 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:17:52,108 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:17:52,108 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:17:52,108 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:17:52,109 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2020-10-20 02:17:52,115 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:17:52,115 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:18:00,128 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:18:00,129 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:18:00,129 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]640
2020-10-20 02:18:00,130 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:00,130 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:00,130 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:18:00,130 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:00,130 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]643
2020-10-20 02:18:00,130 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:00,130 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:00,130 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:18:00,131 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:00,132 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:18:00,135 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:18:00,199 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:18:00,199 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]646
2020-10-20 02:18:00,200 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:00,200 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:00,200 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:18:00,200 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:00,201 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:18:00,243 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:18:00,245 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]649
2020-10-20 02:18:00,247 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:00,247 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:00,247 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:18:00,249 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:00,250 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,214 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:01,215 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:01,216 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:01,217 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:01,218 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:01,218 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:01,218 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:01,218 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:01,218 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,218 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,219 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,219 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,219 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:01,219 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:01,220 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:01,220 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:01,221 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:01,221 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:01,221 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:01,221 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:18:01,221 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:18:01,222 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2020-10-20 02:18:01,229 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:18:01,229 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:18:01,243 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:01,244 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:01,244 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:01,245 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:01,247 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,247 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:01,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:01,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:01,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:01,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:01,249 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:01,249 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:01,251 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:01,251 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:01,252 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:01,252 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:01,252 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,253 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,253 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,253 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,253 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:01,253 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:01,254 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:01,254 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:01,254 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:01,255 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:01,255 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:18:01,255 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:18:01,255 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2020-10-20 02:18:01,261 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:18:01,262 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:18:01,291 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:01,292 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:01,293 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:01,294 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:01,295 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:01,295 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:01,296 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:01,296 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:01,296 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:18:01,296 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:18:01,296 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2020-10-20 02:18:01,301 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:18:01,301 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,302 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:01,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:01,305 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:01,305 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:01,305 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:01,305 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:01,306 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:01,307 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:01,307 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:01,307 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:01,307 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:01,307 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:01,307 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:01,308 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:18:01,308 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:18:01,308 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2020-10-20 02:18:01,313 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:18:01,313 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:18:14,307 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:18:14,308 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]671
2020-10-20 02:18:14,308 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:14,308 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:14,308 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:14,308 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:18:14,309 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:18:14,367 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:18:14,369 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]674
2020-10-20 02:18:14,371 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:14,371 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:14,371 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:18:14,371 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:14,373 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:18:14,417 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:18:14,417 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]677
2020-10-20 02:18:14,418 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:14,418 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:14,418 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:18:14,418 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:14,421 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:18:14,432 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:18:14,433 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]680
2020-10-20 02:18:14,433 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:14,433 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:14,433 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:18:14,435 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:14,435 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:18:15,390 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:15,390 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,390 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:15,390 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:15,391 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:15,392 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:15,392 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:15,395 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:15,395 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,396 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:15,397 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:15,398 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:15,399 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:15,399 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:15,399 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:15,400 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:15,400 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:15,400 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:18:15,400 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:18:15,400 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2020-10-20 02:18:15,408 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:18:15,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:18:15,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:15,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:15,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:15,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,452 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,453 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,453 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:15,453 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,453 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:15,453 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:15,453 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:15,454 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:15,454 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:15,454 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:15,454 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:15,454 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:15,455 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:15,455 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:15,456 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:15,456 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,456 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:15,456 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,457 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,457 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:15,457 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:15,457 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:15,457 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:15,457 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:15,458 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:15,458 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:15,458 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:15,458 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:15,458 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:15,458 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,459 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,459 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,459 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,459 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:15,459 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:15,459 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:15,460 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:15,460 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:15,460 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:15,460 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:18:15,460 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:18:15,460 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:15,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:15,463 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:15,467 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:15,468 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:15,468 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:15,468 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:15,468 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:15,468 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:18:15,468 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:18:15,469 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2020-10-20 02:18:15,469 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:18:15,469 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:18:15,475 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:18:15,475 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:18:15,484 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:15,484 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,484 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:15,484 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:15,485 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:15,486 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:15,486 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,486 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:15,486 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:15,486 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:15,487 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:15,487 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:15,487 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:15,488 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:15,488 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:15,488 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:15,488 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:18:15,489 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:18:15,489 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2020-10-20 02:18:15,493 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:18:32,811 [ERROR] Thread-2 org.pytorch.serve.metrics.MetricCollector - --- Logging error ---
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/677/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 371, in _init
    self.create_time()
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 727, in create_time
    self._create_time = self._proc.create_time()
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1727, in create_time
    ctime = float(self._parse_stat_file()['create_time'])
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=677)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 343, in __init__
    self._init(pid)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 384, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 677

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('677',)
--- Logging error ---
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('677', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/680/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 371, in _init
    self.create_time()
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 727, in create_time
    self._create_time = self._proc.create_time()
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1727, in create_time
    ctime = float(self._parse_stat_file()['create_time'])
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=680)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 343, in __init__
    self._init(pid)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 384, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 680

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('680',)
--- Logging error ---
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('680', 0)
--- Logging error ---
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 449, in wrapper
    ret = self._cache[fun]
AttributeError: _cache

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 452, in wrapper
    return fun(self)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1557, in _parse_stat_file
    with open_binary("%s/%s/stat" % (self._procfs_path, self.pid)) as f:
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_common.py", line 713, in open_binary
    return open(fname, "rb", **kwargs)
FileNotFoundError: [Errno 2] No such file or directory: '/proc/671/stat'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 371, in _init
    self.create_time()
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 727, in create_time
    self._create_time = self._proc.create_time()
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1515, in wrapper
    return fun(self, *args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1727, in create_time
    ctime = float(self._parse_stat_file()['create_time'])
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/_pslinux.py", line 1522, in wrapper
    raise NoSuchProcess(self.pid, self._name)
psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=671)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 20, in get_cpu_usage
    process = psutil.Process(int(pid))
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 343, in __init__
    self._init(pid)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/psutil/__init__.py", line 384, in _init
    raise NoSuchProcess(pid, None, msg)
psutil.NoSuchProcess: psutil.NoSuchProcess no process found with pid 671

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 22, in get_cpu_usage
    logging.error("Failed get process for pid: %s", pid, exc_info=True)
Message: 'Failed get process for pid: %s'
Arguments: ('671',)
--- Logging error ---
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/home/ubuntu/anaconda3/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
BrokenPipeError: [Errno 32] Broken pipe
Call stack:
  File "ts/metrics/metric_collector.py", line 18, in <module>
    check_process_mem_usage(sys.stdin)
  File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/metrics/process_memory_metric.py", line 40, in check_process_mem_usage
    logging.info("%s:%d", process, get_cpu_usage(process))
Message: '%s:%d'
Arguments: ('671', 0)
Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='UTF-8'>
BrokenPipeError: [Errno 32] Broken pipe

2020-10-20 02:18:36,483 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:18:36,483 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]711
2020-10-20 02:18:36,483 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:36,484 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:36,484 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:36,484 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:18:36,486 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:18:36,576 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:18:36,577 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]714
2020-10-20 02:18:36,577 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:36,577 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:36,577 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:36,577 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:18:36,578 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:18:36,589 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:18:36,589 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]717
2020-10-20 02:18:36,590 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:36,590 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:36,590 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:18:36,592 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:36,594 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:18:36,621 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:18:36,624 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]721
2020-10-20 02:18:36,626 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:18:36,626 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:18:36,626 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:18:36,630 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:18:36,632 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:18:37,566 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:37,567 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,567 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:37,567 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:37,567 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,567 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,568 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,568 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,568 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:37,568 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:37,568 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:37,568 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:37,569 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:37,570 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,571 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,572 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,572 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,572 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:37,572 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:37,575 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:37,577 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:37,577 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:37,578 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:37,578 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:37,578 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:18:37,578 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:18:37,578 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2020-10-20 02:18:37,585 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:18:37,585 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:18:37,646 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:37,647 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:37,647 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,648 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:37,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:37,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:37,653 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:37,653 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:37,653 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:37,654 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:37,654 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:37,655 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:37,655 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:18:37,655 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:18:37,655 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:37,655 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:37,656 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:37,662 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:18:37,662 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:18:37,663 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:37,663 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:37,663 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:37,663 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:37,663 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:37,664 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:18:37,664 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:18:37,664 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2020-10-20 02:18:37,670 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:18:37,670 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:18:37,687 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:18:37,688 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:18:37,689 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:18:37,690 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:18:37,690 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:18:37,690 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:18:37,690 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:18:37,690 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:18:37,690 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:18:37,691 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:18:37,691 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:18:37,691 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:18:37,691 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:18:37,691 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:18:37,691 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:18:37,692 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:18:37,692 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:18:37,693 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:18:37,693 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:18:37,693 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:18:37,693 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:18:37,693 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:18:37,693 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:18:37,693 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2020-10-20 02:18:37,698 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:18:37,698 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:19:11,656 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:19:11,656 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]742
2020-10-20 02:19:11,656 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:19:11,656 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:19:11,657 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:19:11,657 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:19:11,659 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:19:11,767 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:19:11,767 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]749
2020-10-20 02:19:11,768 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:19:11,768 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:19:11,768 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:19:11,768 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:19:11,772 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:19:11,774 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:19:11,774 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]746
2020-10-20 02:19:11,774 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:19:11,774 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:19:11,775 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:19:11,775 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:19:11,783 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:19:11,820 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:19:11,822 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]752
2020-10-20 02:19:11,823 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:19:11,823 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:19:11,824 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:19:11,825 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:19:11,827 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:19:12,745 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,746 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,747 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,747 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,747 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:19:12,747 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:19:12,751 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:19:12,751 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:19:12,751 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:19:12,751 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:19:12,752 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:19:12,752 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:19:12,752 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:19:12,752 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 55 seconds.
2020-10-20 02:19:12,760 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:19:12,760 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:19:12,824 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:19:12,824 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:19:12,825 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:19:12,825 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:19:12,825 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:19:12,825 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:19:12,826 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:19:12,827 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:19:12,831 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:19:12,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,833 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,834 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:19:12,834 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:19:12,834 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:19:12,834 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:19:12,834 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:19:12,834 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:19:12,835 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,835 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:19:12,835 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 55 seconds.
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,835 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:19:12,835 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:19:12,836 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:19:12,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:19:12,837 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:19:12,837 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,837 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:19:12,837 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:19:12,837 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:19:12,838 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:19:12,839 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:19:12,841 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:19:12,841 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:19:12,844 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:19:12,844 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:19:12,844 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:19:12,844 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:19:12,845 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:19:12,845 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:19:12,845 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:19:12,845 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:19:12,845 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:19:12,845 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 55 seconds.
2020-10-20 02:19:12,845 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:19:12,845 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:19:12,845 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 55 seconds.
2020-10-20 02:19:12,848 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:19:12,848 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:19:12,852 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:19:12,852 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:19:12,852 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:19:12,852 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:20:07,828 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:20:07,829 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]772
2020-10-20 02:20:07,829 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:20:07,829 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:20:07,829 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:20:07,829 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:20:07,830 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:20:07,946 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:20:07,947 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]775
2020-10-20 02:20:07,947 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:20:07,947 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:20:07,947 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:20:07,947 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:20:07,951 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:20:07,963 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:20:07,963 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]779
2020-10-20 02:20:07,964 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:20:07,964 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:20:07,964 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:20:07,965 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:20:07,965 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:20:07,974 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:20:07,975 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]778
2020-10-20 02:20:07,975 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:20:07,976 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:20:07,976 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:20:07,976 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:20:07,977 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:20:08,902 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:20:08,903 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:08,903 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:20:08,903 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:20:08,903 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:20:08,904 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:20:08,905 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:20:08,905 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:20:08,905 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:20:08,905 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:20:08,905 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:20:08,905 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:20:08,906 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:20:08,907 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:20:08,907 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:20:08,907 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:20:08,907 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:20:08,907 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:08,908 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:08,908 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:08,908 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:08,908 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:20:08,908 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:20:08,910 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:20:08,910 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:20:08,910 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:20:08,911 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:20:08,911 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:20:08,911 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:20:08,913 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:20:08,913 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 89 seconds.
2020-10-20 02:20:08,919 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:20:08,919 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:08,981 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:08,982 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:20:08,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:08,982 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:20:08,982 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:20:08,982 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:20:08,986 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:20:08,986 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:08,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:08,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:20:08,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:20:08,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:20:08,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:20:08,989 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:08,990 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:08,990 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:08,990 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:08,990 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:20:08,990 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:20:08,992 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:20:08,992 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:20:08,992 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:20:08,992 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:20:08,993 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 89 seconds.
2020-10-20 02:20:08,997 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:20:08,997 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:20:09,017 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:20:09,018 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:20:09,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:20:09,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:20:09,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:20:09,020 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:20:09,020 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:20:09,021 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:20:09,021 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:20:09,021 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:20:09,021 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:20:09,021 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 89 seconds.
2020-10-20 02:20:09,028 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:20:09,028 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 84, in load
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name)
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
2020-10-20 02:20:09,035 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap_external>", line 728, in exec_module
2020-10-20 02:20:09,036 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
2020-10-20 02:20:09,036 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FacenetHandler.py", line 7, in <module>
2020-10-20 02:20:09,036 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from FaceDetector import FaceDetector
2020-10-20 02:20:09,036 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/FaceDetector.py", line 3, in <module>
2020-10-20 02:20:09,037 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:20:09,037 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from mtcnn import ONet, PNet, RNet
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/9bf422feda0a4b74a6f0ef313d9ae8e3/mtcnn.py", line 6, in <module>
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     from .utils.detect_face import detect_face, extract_face
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ImportError: attempted relative import with no known parent package
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - During handling of the above exception, another exception occurred:
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - 
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 88, in load
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     module = importlib.import_module(module_name, 'ts.torch_handler')
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/importlib/__init__.py", line 127, in import_module
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _bootstrap._gcd_import(name[level:], package, level)
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
2020-10-20 02:20:09,038 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 983, in _find_and_load
2020-10-20 02:20:09,039 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "<frozen importlib._bootstrap>", line 965, in _find_and_load_unlocked
2020-10-20 02:20:09,039 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ModuleNotFoundError: No module named 'ts.torch_handler.FacenetHandler:handle'
2020-10-20 02:20:09,039 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:20:09,039 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:20:09,039 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:20:09,039 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:20:09,040 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:20:09,040 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:20:09,040 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 89 seconds.
2020-10-20 02:20:09,045 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:20:09,045 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:07,109 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:21:07,110 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:21:07,110 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:21:09,121 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:21:13,157 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:21:13,199 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 02:21:13,293 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 27d23cc7656a4b1b80352adf07f66ad4
2020-10-20 02:21:13,308 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 02:21:13,308 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 02:21:13,308 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 02:21:13,309 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 02:21:13,326 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:21:13,512 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:13,515 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]890
2020-10-20 02:21:13,516 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:13,517 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:21:13,517 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:13,533 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:13,546 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:13,549 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]894
2020-10-20 02:21:13,550 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:13,550 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:21:13,556 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:13,556 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:13,560 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:13,562 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]889
2020-10-20 02:21:13,562 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:13,563 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:21:13,563 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:13,563 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:13,604 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:13,605 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]888
2020-10-20 02:21:13,606 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:13,606 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:21:13,606 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:13,607 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:13,648 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:21:13,648 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:21:13,655 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:21:13,655 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:21:13,657 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:21:13,668 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:13,669 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:13,675 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:13,680 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:14,912 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:14,913 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:14,913 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:14,913 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:14,913 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:14,913 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:14,914 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:14,914 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:14,914 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:14,914 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:14,912 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:14,915 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:14,916 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:14,916 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:14,917 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:14,918 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:14,918 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:14,918 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:14,919 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:14,919 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:14,919 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:14,920 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:14,920 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:14,920 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:14,921 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:14,921 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:14,921 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:14,922 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:14,922 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:14,922 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:14,923 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:14,923 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:14,923 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:14,923 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:14,923 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:14,924 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:14,924 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:14,924 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:14,924 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:14,924 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:14,924 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:14,926 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:14,924 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:14,924 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:14,924 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:14,924 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:14,939 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:14,948 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:14,948 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:14,948 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:14,948 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:14,949 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:14,949 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:14,949 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:14,950 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:14,950 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:14,950 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:14,950 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:14,951 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:14,951 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:14,951 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:14,951 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:14,951 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:14,950 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:14,952 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:14,950 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:14,950 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:14,952 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:14,950 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:14,957 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:14,957 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:14,957 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:14,958 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:14,959 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:14,959 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:14,959 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:14,959 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:14,959 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:14,959 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:14,960 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:14,960 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:14,960 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:14,960 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:14,960 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:14,963 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:14,963 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:14,964 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:14,964 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:14,964 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:14,964 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:14,957 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:14,965 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:14,965 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:14,966 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2020-10-20 02:21:14,953 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:14,966 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:14,966 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:14,966 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:14,966 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2020-10-20 02:21:14,952 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:14,967 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:14,967 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:14,967 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:14,967 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:14,963 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:14,961 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:14,961 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:14,968 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:14,968 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:14,968 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:14,968 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:14,968 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:14,968 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:14,969 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:14,969 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:14,969 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:14,969 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:14,969 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:14,969 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:14,970 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:14,970 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:14,970 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:14,970 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:14,971 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:14,971 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:14,971 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:14,971 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:14,972 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:14,972 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:14,972 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:14,980 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:14,985 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2020-10-20 02:21:14,985 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:14,985 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:14,991 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:14,992 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:14,992 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:14,992 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2020-10-20 02:21:14,992 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:14,992 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:14,999 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:14,999 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:16,081 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:16,083 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]938
2020-10-20 02:21:16,085 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:16,085 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:16,085 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:16,086 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:16,088 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:16,089 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]941
2020-10-20 02:21:16,089 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:16,089 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:16,089 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:16,090 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:16,093 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:16,098 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:16,098 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]944
2020-10-20 02:21:16,098 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:16,098 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:16,099 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:16,099 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:16,106 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:16,121 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:16,129 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:16,130 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]947
2020-10-20 02:21:16,130 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:16,130 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:16,130 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:16,130 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:16,141 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:17,291 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:17,291 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:17,291 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:17,291 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:17,292 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:17,292 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:17,292 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:17,300 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:17,300 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:17,300 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:17,300 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:17,301 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:17,301 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:17,301 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:17,301 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:17,302 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:17,302 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:17,302 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:17,302 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:17,302 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:17,303 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:17,303 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:17,303 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:17,303 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:17,304 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:17,304 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:17,305 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:17,310 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:17,310 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:17,311 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:17,311 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:17,312 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:17,312 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:17,312 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:17,312 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2020-10-20 02:21:17,317 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:17,317 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:17,317 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:17,318 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:17,318 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:17,318 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:17,318 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:17,318 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:17,319 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:17,319 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:17,319 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:17,319 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:17,320 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:17,320 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:17,320 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:17,322 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:17,324 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:17,324 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:17,324 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:17,324 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:17,324 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:17,325 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:17,325 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:17,325 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:17,324 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:17,324 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:17,329 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:17,330 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:17,330 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:17,330 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:17,331 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2020-10-20 02:21:17,331 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:17,332 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:17,332 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:17,332 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:17,332 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:17,332 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2020-10-20 02:21:17,332 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:17,332 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:17,337 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:17,339 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:17,341 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:17,341 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:17,342 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:17,342 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:17,342 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:17,342 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:17,343 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:17,343 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:17,343 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:17,344 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:17,344 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:17,344 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:17,345 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:17,345 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:17,347 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:17,347 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:17,348 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:17,348 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:17,348 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2020-10-20 02:21:17,348 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:17,354 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:18,422 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:18,423 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]965
2020-10-20 02:21:18,424 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:18,424 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:18,424 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:18,424 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:18,429 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:18,443 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:18,443 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]968
2020-10-20 02:21:18,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:18,444 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:18,444 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:18,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:18,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:18,459 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:18,461 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]974
2020-10-20 02:21:18,462 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:18,462 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:18,462 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:18,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:18,466 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:18,472 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:18,472 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]977
2020-10-20 02:21:18,472 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:18,472 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:18,472 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:18,473 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:18,474 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:19,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:19,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:19,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:19,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:19,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:19,643 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:19,644 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:19,645 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:19,649 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:19,649 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:19,649 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:19,649 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:19,650 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:19,650 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:19,650 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:19,650 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2020-10-20 02:21:19,650 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:19,650 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:19,650 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:19,650 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:19,650 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:19,650 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:19,651 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:19,652 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:19,653 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:19,653 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:19,653 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:19,654 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:19,655 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:19,655 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:19,655 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:19,655 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2020-10-20 02:21:19,661 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:19,661 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:19,666 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:19,666 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:19,716 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:19,716 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:19,717 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:19,718 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:19,719 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:19,719 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:19,719 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:19,719 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:19,720 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:19,721 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:19,721 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:19,721 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:19,721 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:19,717 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:19,723 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:19,723 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:19,723 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:19,724 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:19,724 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:19,724 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:19,724 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2020-10-20 02:21:19,724 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:19,724 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:19,724 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:19,724 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:19,725 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:19,726 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:19,728 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:19,728 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:19,728 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:19,729 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:19,729 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:19,729 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:19,729 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:19,729 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2020-10-20 02:21:19,731 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:19,731 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:19,735 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:19,735 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:21,741 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:21,741 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1003
2020-10-20 02:21:21,741 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:21,741 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:21,742 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:21,742 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:21,744 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:21,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:21,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1006
2020-10-20 02:21:21,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:21,750 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:21,750 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:21,753 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:21,754 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:21,846 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:21,846 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1009
2020-10-20 02:21:21,847 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:21,847 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:21,847 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:21,847 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:21,849 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:21,870 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:21,871 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1011
2020-10-20 02:21:21,871 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:21,871 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:21,871 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:21,871 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:21,875 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:22,909 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:22,910 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:22,910 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:22,911 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:22,912 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:22,913 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:22,913 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:22,913 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:22,913 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:22,914 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:22,914 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:22,914 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:22,915 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:22,915 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:22,915 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:22,915 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:22,915 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2020-10-20 02:21:22,922 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:22,922 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:22,938 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:22,938 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:22,938 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:22,938 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:22,938 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:22,939 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:22,940 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:22,941 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:22,943 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:22,943 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:22,943 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:22,944 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:22,944 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:22,944 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:22,944 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:22,944 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2020-10-20 02:21:22,953 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:22,953 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:23,029 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:23,030 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:23,031 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:23,031 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:23,032 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:23,032 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:23,032 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:23,033 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:23,033 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:23,033 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:23,034 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:23,034 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2020-10-20 02:21:23,034 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:23,040 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:23,048 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:23,048 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:23,049 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:23,049 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:23,049 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:23,050 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:23,050 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:23,050 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:23,050 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:23,050 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2020-10-20 02:21:23,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:23,051 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:23,056 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:26,001 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:26,001 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1036
2020-10-20 02:21:26,002 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:26,002 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:26,002 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:26,002 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:26,004 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:26,044 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:26,045 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1039
2020-10-20 02:21:26,045 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:26,045 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:26,047 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:26,047 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:26,047 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:26,154 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:26,155 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1042
2020-10-20 02:21:26,155 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:26,155 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:26,155 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:26,155 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:26,157 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:26,169 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:26,169 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1045
2020-10-20 02:21:26,169 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:26,169 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:26,170 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:26,170 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:26,171 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:27,187 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:27,187 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:27,187 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:27,187 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:27,187 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:27,188 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:27,189 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:27,190 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:27,191 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:27,192 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:27,192 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:27,192 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:27,192 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:27,193 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:27,193 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:27,193 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:27,193 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2020-10-20 02:21:27,200 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:27,200 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:27,225 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:27,225 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:27,225 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:27,225 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:27,226 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:27,226 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:27,226 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:27,226 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:27,228 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:27,232 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:27,232 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:27,232 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:27,232 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:27,232 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:27,232 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:27,233 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:27,233 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:27,233 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:27,233 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:27,233 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:27,233 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:27,237 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:27,238 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:27,238 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:27,238 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:27,238 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2020-10-20 02:21:27,245 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:27,246 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:27,292 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:27,292 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:27,293 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:27,294 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:27,294 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:27,294 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:27,294 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:27,294 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:27,294 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:27,295 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:27,295 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:27,296 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:27,296 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:27,296 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:27,296 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:27,296 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2020-10-20 02:21:27,302 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:27,302 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:27,308 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:27,309 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:27,309 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:27,310 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:27,310 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:27,312 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:27,312 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:27,312 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:27,312 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:27,312 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:27,312 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:27,312 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2020-10-20 02:21:27,318 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:32,281 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:32,281 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1066
2020-10-20 02:21:32,281 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:32,281 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:32,281 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:32,281 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:32,282 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:32,338 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:32,339 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1070
2020-10-20 02:21:32,339 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:32,339 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:32,339 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:32,344 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:32,344 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:32,417 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:32,417 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1073
2020-10-20 02:21:32,417 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:32,417 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:32,418 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:32,418 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:32,424 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:32,442 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:32,443 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1077
2020-10-20 02:21:32,443 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:32,443 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:32,443 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:32,444 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:32,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:33,463 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:33,463 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:33,463 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:33,464 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:33,465 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:33,465 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:33,465 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:33,468 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:33,468 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:33,469 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:33,469 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:33,469 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:33,470 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:33,470 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:33,470 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2020-10-20 02:21:33,479 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:33,479 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:33,492 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:33,493 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:33,494 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:33,494 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:33,494 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:33,495 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:33,495 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:33,495 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:33,495 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:33,495 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2020-10-20 02:21:33,502 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:33,502 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:33,562 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:33,562 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:33,562 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:33,562 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:33,563 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:33,563 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:33,564 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:33,564 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:33,564 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:33,565 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:33,566 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:33,566 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:33,566 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:33,566 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:33,567 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:33,567 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:33,567 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:33,567 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:33,567 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:33,567 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:33,567 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2020-10-20 02:21:33,567 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:33,572 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:33,595 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:33,595 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:33,595 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:33,595 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:33,595 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:33,596 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:33,596 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:33,597 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:33,597 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:33,597 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:33,597 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:33,597 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:33,597 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:33,597 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:33,598 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:33,599 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:33,599 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:33,599 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:33,599 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2020-10-20 02:21:33,604 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:33,604 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:41,549 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:41,549 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1106
2020-10-20 02:21:41,549 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:41,549 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:41,549 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:41,549 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:41,550 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:41,585 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:41,585 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1109
2020-10-20 02:21:41,586 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:41,586 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:41,586 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:41,586 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:41,587 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:41,680 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:41,680 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1112
2020-10-20 02:21:41,680 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:41,681 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:41,681 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:41,682 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:41,684 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:41,723 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:41,725 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1116
2020-10-20 02:21:41,727 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:41,727 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:41,727 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:41,730 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:41,732 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:42,730 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:42,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:42,732 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:42,732 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:42,732 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:42,732 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:42,732 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:42,733 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:42,737 [INFO ] epollEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:42,737 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:42,738 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:42,738 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:42,738 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:42,739 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:42,739 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:42,739 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2020-10-20 02:21:42,747 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:42,747 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:42,749 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:42,750 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:42,751 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:42,751 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:42,751 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:42,752 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:42,752 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:42,752 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:42,753 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:42,753 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2020-10-20 02:21:42,759 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:42,760 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:42,834 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:42,834 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:42,834 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:42,834 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:42,835 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:42,837 [INFO ] epollEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:42,837 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:42,839 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:42,839 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:42,839 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:42,840 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:42,840 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:42,840 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:42,840 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2020-10-20 02:21:42,840 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:42,846 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:42,888 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:42,889 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:42,890 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:42,890 [INFO ] epollEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:42,891 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:42,892 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:42,894 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:42,894 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:42,894 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:42,894 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:42,894 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2020-10-20 02:21:42,899 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:21:42,899 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:55,818 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:21:55,819 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1138
2020-10-20 02:21:55,819 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:55,819 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:55,819 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:55,819 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:21:55,820 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:21:55,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:21:55,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1141
2020-10-20 02:21:55,837 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:55,838 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:55,838 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:55,838 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:21:55,839 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:21:55,934 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:21:55,934 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1144
2020-10-20 02:21:55,935 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:55,935 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:55,935 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:21:55,937 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:55,937 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:21:56,020 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:21:56,022 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1147
2020-10-20 02:21:56,024 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:21:56,024 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2020-10-20 02:21:56,024 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:21:56,028 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:21:56,029 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:21:56,986 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:56,986 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:56,987 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:56,988 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:56,989 [INFO ] epollEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:56,990 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:56,991 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:56,992 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:56,992 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:56,994 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stderr
2020-10-20 02:21:56,994 [WARN ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-facenet_1.0-stdout
2020-10-20 02:21:56,994 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2020-10-20 02:21:57,001 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stdout
2020-10-20 02:21:57,001 [INFO ] W-9003-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-facenet_1.0-stderr
2020-10-20 02:21:57,012 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:57,015 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:57,016 [INFO ] epollEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:57,017 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:57,017 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:57,017 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:57,017 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:57,018 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:57,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:57,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:57,025 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:57,026 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return _open_file(name_or_buffer, mode)
2020-10-20 02:21:57,027 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 210, in __init__
2020-10-20 02:21:57,027 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     super(_open_file, self).__init__(open(name, mode))
2020-10-20 02:21:57,027 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - FileNotFoundError: [Errno 2] No such file or directory: '/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/../data/pnet.pt'
2020-10-20 02:21:57,027 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:57,027 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:57,028 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:57,028 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:57,028 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stderr
2020-10-20 02:21:57,028 [WARN ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-facenet_1.0-stdout
2020-10-20 02:21:57,028 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2020-10-20 02:21:57,035 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stdout
2020-10-20 02:21:57,035 [INFO ] W-9002-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-facenet_1.0-stderr
2020-10-20 02:21:57,103 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     entry_point(None, service.context)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 83, in handle
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     _service.initialize(context)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FacenetHandler.py", line 37, in initialize
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.model = FaceDetector(device=self.device)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/FaceDetector.py", line 24, in __init__
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.pnet = PNet()
2020-10-20 02:21:57,104 [INFO ] epollEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/27d23cc7656a4b1b80352adf07f66ad4/mtcnn.py", line 31, in __init__
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     state_dict = torch.load(state_dict_path)
2020-10-20 02:21:57,104 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 571, in load
2020-10-20 02:21:57,105 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:57,105 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     with _open_file_like(f, 'rb') as opened_file:
2020-10-20 02:21:57,105 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:57,105 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py", line 229, in _open_file_like
2020-10-20 02:21:57,105 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:57,105 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:57,105 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stderr
2020-10-20 02:21:57,106 [WARN ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-facenet_1.0-stdout
2020-10-20 02:21:57,106 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2020-10-20 02:21:57,106 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stdout
2020-10-20 02:21:57,112 [INFO ] W-9000-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-facenet_1.0-stderr
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Backend worker process died.
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 176, in <module>
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     worker.run_server()
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 148, in run_server
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     self.handle_connection(cl_socket)
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 112, in handle_connection
2020-10-20 02:21:57,185 [INFO ] epollEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service, result, code = self.load_model(msg)
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_service_worker.py", line 85, in load_model
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     service = model_loader.load(model_name, model_dir, handler, gpu, batch_size)
2020-10-20 02:21:57,185 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2020-10-20 02:21:57,185 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056)
	at java.base/java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133)
	at java.base/java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432)
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:129)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
2020-10-20 02:21:57,186 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: facenet, error: Worker died.
2020-10-20 02:21:57,185 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/model_loader.py", line 101, in load
2020-10-20 02:21:57,186 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2020-10-20 02:21:57,186 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stderr
2020-10-20 02:21:57,186 [WARN ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-facenet_1.0-stdout
2020-10-20 02:21:57,186 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2020-10-20 02:21:57,187 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stdout
2020-10-20 02:21:57,192 [INFO ] W-9001-facenet_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-facenet_1.0-stderr
2020-10-20 02:22:10,089 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:22:10,089 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:22:10,089 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:22:12,106 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:22:18,108 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:22:18,148 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 02:22:18,239 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 87000b5969934bf28ac0a1baf92409f2
2020-10-20 02:22:18,251 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 02:22:18,252 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 02:22:18,252 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 02:22:18,252 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 02:22:18,270 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:22:18,410 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:22:18,430 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1254
2020-10-20 02:22:18,429 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:22:18,431 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:22:18,431 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:22:18,432 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:22:18,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1252
2020-10-20 02:22:18,445 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:22:18,445 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:22:18,446 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:22:18,483 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:22:18,485 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:22:18,486 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:22:18,488 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1253
2020-10-20 02:22:18,488 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:22:18,489 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:22:18,489 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:22:18,489 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:22:18,490 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:22:18,489 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1255
2020-10-20 02:22:18,494 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:22:18,494 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:22:18,494 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:22:18,494 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:22:18,501 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:22:18,501 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:22:18,506 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:22:18,507 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:22:18,508 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:22:18,532 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:22:18,532 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:22:18,533 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:22:18,534 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:22:19,819 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1216
2020-10-20 02:22:19,820 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:22:19,823 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237
2020-10-20 02:22:19,825 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:22:19,830 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1205
2020-10-20 02:22:19,831 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:22:19,837 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230
2020-10-20 02:22:19,838 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:22:51,884 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 582
2020-10-20 02:22:51,887 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 230411, Backend time ns: 586546081
2020-10-20 02:28:44,727 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 02:28:44,727 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 02:28:44,729 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 02:28:46,841 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 02:28:52,596 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 02:28:52,639 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 02:28:52,737 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 8c348a9a177d469bb961324ef8cfb6f7
2020-10-20 02:28:52,754 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 02:28:52,754 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 02:28:52,754 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 02:28:52,754 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 02:28:52,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 02:28:53,006 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 02:28:53,009 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 02:28:53,009 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1589
2020-10-20 02:28:53,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:28:53,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:28:53,010 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1590
2020-10-20 02:28:53,010 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:28:53,010 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 02:28:53,010 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:28:53,010 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:28:53,029 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:28:53,028 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1591
2020-10-20 02:28:53,029 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:28:53,030 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:28:53,030 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:28:53,033 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 02:28:53,033 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 02:28:53,034 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 02:28:53,043 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 02:28:53,044 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]1597
2020-10-20 02:28:53,044 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 02:28:53,047 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 02:28:53,047 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 02:28:53,047 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 02:28:53,062 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 02:28:53,068 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 02:28:53,068 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 02:28:53,071 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 02:28:53,074 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 02:28:53,074 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 02:28:53,074 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 02:28:53,078 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 02:28:53,081 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 02:28:54,409 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242
2020-10-20 02:28:54,409 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:28:54,410 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243
2020-10-20 02:28:54,410 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1215
2020-10-20 02:28:54,411 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:28:54,411 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:28:54,418 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251
2020-10-20 02:28:54,419 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 02:30:00,136 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 571
2020-10-20 02:30:00,138 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 320072, Backend time ns: 574255756
2020-10-20 04:14:24,233 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 572
2020-10-20 04:14:24,235 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 131370, Backend time ns: 575066334
2020-10-20 04:17:54,467 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 622
2020-10-20 04:17:54,468 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 112490, Backend time ns: 624152880
2020-10-20 04:41:04,380 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 04:41:04,380 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 04:41:04,383 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 04:41:06,400 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 04:41:14,278 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: https://0.0.0.0:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 04:41:14,321 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 04:41:14,416 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 013100936a644735b54c2baa62d606fd
2020-10-20 04:41:14,430 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 04:41:14,431 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 04:41:14,431 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 04:41:14,431 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 04:41:14,451 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 04:41:14,588 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 04:41:14,592 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3588
2020-10-20 04:41:14,593 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:41:14,593 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:41:14,594 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:41:14,606 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 04:41:14,609 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3590
2020-10-20 04:41:14,609 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:41:14,610 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 04:41:14,610 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:41:14,611 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 04:41:14,611 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:41:14,644 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 04:41:14,647 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3589
2020-10-20 04:41:14,648 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:41:14,648 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:41:14,648 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:41:14,648 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 04:41:14,654 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 04:41:14,657 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3591
2020-10-20 04:41:14,657 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:41:14,658 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:41:14,658 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:41:14,658 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 04:41:14,816 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 04:41:14,819 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 04:41:14,821 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 04:41:14,822 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 04:41:16,720 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: https://0.0.0.0:8080
2020-10-20 04:41:16,721 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 04:41:16,737 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 04:41:16,740 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 04:41:16,741 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 04:41:16,748 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1853
2020-10-20 04:41:16,749 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:41:16,868 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1976
2020-10-20 04:41:16,868 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:41:16,881 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1982
2020-10-20 04:41:16,881 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:41:16,974 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2073
2020-10-20 04:41:16,974 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:41:37,859 [ERROR] epollEventLoopGroup-3-1 org.pytorch.serve.http.HttpRequestHandler - 
io.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:471)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:792)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1246)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1314)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440)
	... 15 more
2020-10-20 04:42:31,201 [ERROR] epollEventLoopGroup-3-2 org.pytorch.serve.http.HttpRequestHandler - 
io.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:471)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:792)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1246)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1314)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440)
	... 15 more
2020-10-20 04:42:34,552 [ERROR] epollEventLoopGroup-3-3 org.pytorch.serve.http.HttpRequestHandler - 
io.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:471)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:792)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1246)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1314)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440)
	... 15 more
2020-10-20 04:42:41,504 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 04:42:41,504 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 04:42:41,505 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 04:42:43,524 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 04:42:49,397 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 04:42:49,436 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 04:42:49,527 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 942ab33e853445b7a359308a1e686a01
2020-10-20 04:42:49,542 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 04:42:49,543 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 04:42:49,543 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 04:42:49,543 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 04:42:49,563 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 04:42:49,726 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 04:42:49,729 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3787
2020-10-20 04:42:49,729 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:42:49,730 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:42:49,730 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:42:49,731 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 04:42:49,734 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3788
2020-10-20 04:42:49,734 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:42:49,735 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:42:49,736 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:42:49,745 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 04:42:49,749 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 04:42:49,775 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 04:42:49,779 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3786
2020-10-20 04:42:49,793 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:42:49,793 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 04:42:49,793 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:42:49,793 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:42:49,793 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 04:42:49,795 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]3785
2020-10-20 04:42:49,795 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:42:49,795 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:42:49,795 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:42:49,795 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 04:42:49,824 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 04:42:49,824 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 04:42:49,825 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 04:42:49,826 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 04:42:49,826 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 04:42:49,828 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 04:42:49,833 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 04:42:49,834 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 04:42:49,842 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 04:42:51,127 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1220
2020-10-20 04:42:51,127 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:42:51,144 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1220
2020-10-20 04:42:51,145 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:42:51,195 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295
2020-10-20 04:42:51,195 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:42:51,236 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307
2020-10-20 04:42:51,236 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:42:53,696 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 562
2020-10-20 04:42:53,699 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 221701, Backend time ns: 565742927
2020-10-20 04:54:16,231 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 04:54:16,231 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 04:54:16,232 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 04:54:18,247 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 04:54:20,543 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: https://0.0.0.0:8080
Management address: https://0.0.0.0:8081
Metrics address: https://0.0.0.0:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 04:54:20,588 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 04:54:20,690 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag c64c085980e64524be89c36a5c9b508f
2020-10-20 04:54:20,706 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 04:54:20,707 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 04:54:20,707 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 04:54:20,707 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 04:54:20,726 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 04:54:20,865 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 04:54:20,877 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4100
2020-10-20 04:54:20,878 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:54:20,878 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:54:20,879 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:54:20,898 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 04:54:20,903 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 04:54:20,905 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4101
2020-10-20 04:54:20,906 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:54:20,906 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:54:20,907 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:54:20,907 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 04:54:20,913 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 04:54:20,914 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4102
2020-10-20 04:54:20,915 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:54:20,915 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:54:20,915 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:54:20,915 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 04:54:20,963 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 04:54:20,966 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4107
2020-10-20 04:54:20,966 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:54:20,967 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:54:20,967 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:54:20,967 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 04:54:21,105 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 04:54:21,117 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 04:54:21,122 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 04:54:21,124 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 04:54:21,771 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: https://0.0.0.0:8080
2020-10-20 04:54:21,771 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 04:54:22,010 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: https://0.0.0.0:8081
2020-10-20 04:54:22,010 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 04:54:22,296 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: https://0.0.0.0:8082
2020-10-20 04:54:22,912 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1713
2020-10-20 04:54:22,913 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:54:22,920 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1726
2020-10-20 04:54:22,920 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:54:22,953 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1745
2020-10-20 04:54:22,953 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:54:23,001 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1786
2020-10-20 04:54:23,002 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:54:31,450 [ERROR] epollEventLoopGroup-3-1 org.pytorch.serve.http.HttpRequestHandler - 
io.netty.handler.codec.DecoderException: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 504f5354202f70726564696374696f6e732f666163656e657420485454502f312e310d0a486f73743a206c6f63616c686f73743a383038300d0a557365722d4167656e743a20707974686f6e2d72657175657374732f322e32322e300d0a4163636570742d456e636f64696e673a20677a69702c206465666c6174650d0a4163636570743a202a2f2a0d0a436f6e6e656374696f6e3a206b6565702d616c6976650d0a436f6e74656e742d4c656e6774683a203330313039340d0a436f6e74656e742d547970653a206d756c7469706172742f666f726d2d646174613b20626f756e646172793d62383661373365386130636365613166346665343038323537323433643664330d0a0d0a2d2d62383661373365386130636365613166346665343038323537323433643664330d0a436f6e74656e742d446973706f736974696f6e3a20666f726d2d646174613b206e616d653d227468726573686f6c64220d0a0d0a302e370d0a2d2d62383661373365386130636365613166346665343038323537323433643664330d0a436f6e74656e742d446973706f736974696f6e3a20666f726d2d646174613b206e616d653d2266696c65223b2066696c656e616d653d226d756c7469666163652e6a7067220d0a0d0affd8ffe000104a46494600010101004800480000ffe1022245786966000049492a000800000009000e010200150100007a0000001201030001000000010000001a01050001000000900100001b0105000100000098010000280103000100000002000000310102001e000000a0010000320102001a000000be0100009882020011000000d80100006987040001000000ea01000000000000465249454e4453202d2d2050696374757265643a2028636c6f636b776973652066726f6d20746f70206c65667429204a656e6e6966657220416e6973746f6e2061732052616368656c20477265656e2c204d617474686577205065727279206173204368616e646c65722042696e672c2044617669642053636877696d6d657220617320526f73732047656c6c65722c20204c697361204b7564726f772061732050686f656265204275666661792c204d617474204c65426c616e63206173204a6f657920547269626269616e692c20436f757274656e657920436f78204172717565747465206173204d6f6e6963612047656c6c6572202d2d2050686f746f2062793a204e4243552050686f746f2042616e6b00002c010000010000002c0100000100000041646f62652050686f746f73686f7020435333204d6163696e746f736800323031382d30312d32325431393a35383a33362d30353a303000c2a9204e424320556e6976657273616c0000030000900700040000003032323002a00400010000000807000003a0040001000000ef08000000000000ef0800000000ffed042450686f746f73686f7020332e30003842494d04040000000003eb1c015a00031b25471c0200000200021c02780131465249454e4453202d2d2050696374757265643a2028636c6f636b776973652066726f6d20746f70206c65667429204a656e6e6966657220416e6973746f6e2061732052616368656c20477265656e2c204d617474686577205065727279206173204368616e646c65722042696e672c2044617669642053636877696d6d657220617320526f73732047656c6c65722c204c697361204b7564726f772061732050686f656265204275666661792c204d617474204c65426c616e63206173204a6f657920547269626269616e692c20436f757274656e657920436f78206173204d6f6e6963612047656c6c657220202d2d202850686f746f206279205265697369672026205461796c6f722f4e42432f4e4243552050686f746f2042616e6b2076696120476574747920496d61676573291c027a0002494d1c02690012467269656e6473202d20536561736f6e20311c022800ff4e6f742052656c656173656420284e522920466f7220656469746f7269616c20757365206f6e6c792e204164646974696f6e616c20636c656172616e636520726571756972656420666f7220636f6d6d65726369616c206f722070726f6d6f74696f6e616c207573652c20636f6e7461637420796f7572206c6f63616c206f666669636520666f7220617373697374616e63652e20c2a0416e7920636f6d6d65726369616c206f722070726f6d6f74696f6e616c20757365206f66204e4243556e6976657273616c20636f6e74656e74207265717569726573204e4243556e6976657273616c2773207072696f72207772697474656e20636f6e73656e742e1c025000034e42431c0255000b436f6e7472696275746f721c026e00144e42432076696120476574747920496d616765731c0273000c4e4243556e6976657273616c1c0205000f4e55505f3030303530305f303034351c0237000831393934303631351c025a000742757262616e6b1c025f000a43616c69666f726e69611c0265000d556e69746564205374617465731c026700093138323435323538321c020f0001451c0214000354454c1c021400034143451c0219000531393930731c02190009313939342d313939351c02190005436f6c6f721c02190006436f6d6564791c0219000747616c6c6572791c0219000a4e55505f3030303530301c02190008506f7274726169741c02190004436173741c0219000b45796520436f6e746163741c0219000547726f75701c021900074f7574646f6f721c021900076f7574736964651c02190007536d696c696e671c0274001732303132204e4243556e6976657273616c2c20496e632e1c023c000b3030303030302b303030301c02640003555341003842494d04250000000000105cd279e293f04605c9cb48f4d03088feffdb004300030202020202030202020303030304060404040404080606050609080a0a090809090a0c0f0c0a0b0e0b09090d110d0e0f101011100a0c12131210130f101010ffdb00430103030304030408040408100b090b1010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010101010ffc2001108027604b003011100021101031101ffc4001c0000010501010100000000000000000000050203040607010008ffc4001b01000301010101010000000000000000000001020304050607ffda000c03010002100310000001cbf9fa560a9a704e0a2baf0b835b97051ee5b9b5a7d4db06748999b0cacf6751b58554a53f22521f96d31a6705e0e2a712e0fa9f952895dc2669d96caa63498bac466df95c1f132959bf011a4e30e6b9b62d39e72d23884269065b421e6940f0791d6923509a06c794ec1e973045c54c6f086426ef88792a68cedce7f9ddfdcfb58f65a10cde654f49d33d110466e6085b3e7d4684330185c9f4cd19edcba95839ef27ea2373db334e3473a70039d8d0bdef9329f30b998d75884d6d783a848d4ce52f23a1d96a6b88533c8eb12840fa2533a1e1786904b494d69cb0a3ba1c392d4a63a958de67a8bbd8ca14da86eb4dc8ed18ef2f4799d97d471880e0d40a7321a8ed4729d97d4d09b371265d7cb3723149fa8e4d741e13b9da83b52a1258da7d079094d23552ed4f936e5f934b50ed30abb72a136322f2979d6a7b65d6c10a352d2d4cf68f426111ca658d22632412e8247d0f0bc0d8343cab50ea72d22019ed1f3faa893522914088913b4161df5a1d68f247a2b2a66a9a459d33516a08e1f35235da59ecb3ecd5dba4381fa45ff1d704b4379f56a1c864bdf32b5343caadbb41cb8851769c2e42101e0f036850394940917810aba2e3161e04a1a04a7e6750869a4d4c409a54911419e666aa86512414824458348323b7db691105d43cc404a6f1ce7dd20a9a507848671af27d6941ea96937a6bb14d2a6ae1c457dd19938d3d52d2a521f14b8af23cd32ce8719e4d48e0706869c6908750eb22846b4c94a17aa6394fb8b0668a513a94aa8645a3d4904ac1092364430b8ed1109e26c1d1703a3e89b061bcb3556554a4b3d6f114d89a747c0421b476a6eda45da5c7696e45c58aa579a99ec3d16c33c8f97a5fd2d73f35c57d1fa22b354d26bda46ad9dfceccf63a38a9094a137b45573ad1e573af2849918ab0e15d4dfb97c51d37d8a43a0c8394211c12c3c1e6783888f350d3e879a690d2a741807a9134116674e83b2504b24cb82ac2ccb3db83294df50b67424b318e6dfccea7d6b8d2d3ea4a1a58b121a6824a7ecf44a6c691c90436513790a6b916a6b952e453a096a48a3d11934aa50ba3f071ae39e0dd91c1476d152a55c04398edb8e6c6a2753f4b31a65087a83cc88ec509226002bb587846c81cea7a3c25820194db6661b234ab201e73153685b4ccd3211d0c21a44ca5bade720552a29b969a9e90fb43dabd4dca0a5a30d46d63c192fa3db72955e4a9e93b745fcccc918da669fa9710ea6e351ae64eb046e614d5830b73372694814d19272a1ad91d03538c8535c624380964587d6464d2cf222a1a4cdb53c1aa52e6a4b59f143e8989117241c95a0f308b1a97228e0de14607030fc755b5e4fc0e0707c27a3e8d4248d0294abd2fd34ce90a90230d457536e9753509372d4b436b12da61096d21c0ea3c086b8d362747c1320b64c96d3491b405196820c52584a14e5572bc8c225c8d02462d3780a34e83c93ad787c1786d2481e47b05c7f374d986229429691c796d8424a3874349bcf43273c28327f44daad8b39b5b14d3818e49011621e70871966a9b42aa4d4edb15f3300786d35a1ed04d149c755a63c0fed99ab98e36a1d0b3a484d47d0222a0a62c02860535c04870381e048243a090e8d2265a949ec423d2e1d2209f25d1183e89e911a82144e0b130c5092a3a4e8d2115294cc4736e34a6281e44863a1e13e0ba3a8eaa589da4947849079b58281123ec48392e002c12248dd1343759d43ac482438253691369b487412c691c17472c240782530a22c33a234cbc8a40d99686120382be8a508bc8804b24a5e6203c155b282eb12566a6a00d60393607e44126189972547a1de6326a052d06a618525bd8853d57ce306dd6a9f2f3d96c27a054ce60b16c2cf986284090cb00de4e32200446ac7a41c6ccdc0e9aac6755e96411f45b4729f01c60093e7d9129a83ce7c348fc8535e4fc1e1474e0d2209ec622715cd227c54b0cfd90da7409399cc9ecb2504471d0f5344a75b8a9701895c136df5290da98844907448050dc4258b49f0f314084fc129aecb683a130184d552b050291e05a38da9279b58bc0f0486949b60f078148582416c750a0f028160a0e0ba3e074120d2422aab3b4d8720826ea1d06c196728f2324aac855f72db55e3eeb84103474b657da8b50037e589ae282769331099fa567a2b49e4e3b4b90f343dab05c82cea97353a96b6ca24964a57817cd99e832a7c164604922b3c1e03f73611cfb8e8448ba0c39a3fa49ab037c05b5568581aae23acf07438094bcdf5090e024038101ecd28c21368bcd3ed5002135d09c29edcb6ae14c8b20c9e6781a06d04d977ce5609171884d60a05a3cc5a5e675af23a1c0e878694d0d750e33c0a12d3e35d4fcd713ea38ce879aea7e6bc1d0e0fd2f8d743c1d678132d5492858f80805874120a0e0bc3f0b89a1831ba06d375cc2f14e1294f8c607c06a8c65d6371b68596df49f9fd456e1cd6457
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:471)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:792)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: io.netty.handler.ssl.NotSslRecordException: not an SSL/TLS record: 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
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1246)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1314)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440)
	... 15 more
2020-10-20 04:54:45,999 [ERROR] epollEventLoopGroup-3-2 org.pytorch.serve.http.HttpRequestHandler - 
io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: Received fatal alert: unknown_ca
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:471)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:276)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:357)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1410)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:379)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:365)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:919)
	at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:792)
	at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:475)
	at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:378)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: javax.net.ssl.SSLHandshakeException: Received fatal alert: unknown_ca
	at java.base/sun.security.ssl.Alert.createSSLException(Alert.java:131)
	at java.base/sun.security.ssl.Alert.createSSLException(Alert.java:117)
	at java.base/sun.security.ssl.TransportContext.fatal(TransportContext.java:313)
	at java.base/sun.security.ssl.Alert$AlertConsumer.consume(Alert.java:293)
	at java.base/sun.security.ssl.TransportContext.dispatch(TransportContext.java:186)
	at java.base/sun.security.ssl.SSLTransport.decode(SSLTransport.java:171)
	at java.base/sun.security.ssl.SSLEngineImpl.decode(SSLEngineImpl.java:681)
	at java.base/sun.security.ssl.SSLEngineImpl.readRecord(SSLEngineImpl.java:636)
	at java.base/sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:454)
	at java.base/sun.security.ssl.SSLEngineImpl.unwrap(SSLEngineImpl.java:433)
	at java.base/javax.net.ssl.SSLEngine.unwrap(SSLEngine.java:637)
	at io.netty.handler.ssl.SslHandler$SslEngineType$3.unwrap(SslHandler.java:282)
	at io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1372)
	at io.netty.handler.ssl.SslHandler.decodeJdkCompatible(SslHandler.java:1267)
	at io.netty.handler.ssl.SslHandler.decode(SslHandler.java:1314)
	at io.netty.handler.codec.ByteToMessageDecoder.decodeRemovalReentryProtection(ByteToMessageDecoder.java:501)
	at io.netty.handler.codec.ByteToMessageDecoder.callDecode(ByteToMessageDecoder.java:440)
	... 15 more
2020-10-20 04:58:09,872 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 04:58:09,875 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 04:58:09,872 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 04:58:11,891 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 04:58:17,864 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 04:58:17,902 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 04:58:17,993 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag e68561098a0b48f4ab5671c343c607f4
2020-10-20 04:58:18,007 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 04:58:18,008 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 04:58:18,008 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 04:58:18,008 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 04:58:18,028 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 04:58:18,248 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 04:58:18,248 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 04:58:18,249 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 04:58:18,253 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4376
2020-10-20 04:58:18,253 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4377
2020-10-20 04:58:18,253 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4378
2020-10-20 04:58:18,254 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:58:18,254 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:58:18,254 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:58:18,255 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:58:18,255 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:58:18,255 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:58:18,255 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:58:18,257 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:58:18,258 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 04:58:18,258 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:58:18,260 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4379
2020-10-20 04:58:18,260 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 04:58:18,260 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 04:58:18,261 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 04:58:18,265 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2020-10-20 04:58:18,265 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 04:58:18,268 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 04:58:18,268 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 04:58:18,268 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2020-10-20 04:58:18,268 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 04:58:18,268 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 04:58:18,269 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 04:58:18,276 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 04:58:18,303 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 04:58:18,303 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 04:58:18,303 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 04:58:18,304 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 04:58:19,595 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1212
2020-10-20 04:58:19,596 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228
2020-10-20 04:58:19,596 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:58:19,596 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1209
2020-10-20 04:58:19,596 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:58:19,597 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 04:58:19,600 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1217
2020-10-20 04:58:19,600 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:28,592 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:09:28,592 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:09:28,594 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:09:30,608 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:09:36,594 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:09:36,634 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:09:36,725 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 16e412a719df4c28be19d17997a9d2a1
2020-10-20 05:09:36,739 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:09:36,739 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:09:36,739 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:09:36,739 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:09:36,758 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:09:36,921 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:09:36,922 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:09:36,924 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4611
2020-10-20 05:09:36,924 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:36,924 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:36,925 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4614
2020-10-20 05:09:36,925 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:36,925 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:36,925 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:36,925 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:36,946 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:09:36,946 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:09:36,948 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4612
2020-10-20 05:09:36,947 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:09:36,948 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:36,949 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:36,950 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:09:36,950 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:36,951 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:09:36,955 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4615
2020-10-20 05:09:36,956 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:36,956 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:36,956 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:36,956 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:09:37,035 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2020-10-20 05:09:37,035 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:09:37,044 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:09:37,049 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:09:37,049 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:09:37,049 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2020-10-20 05:09:37,049 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:09:37,050 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:09:37,055 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:09:38,355 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223
2020-10-20 05:09:38,356 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224
2020-10-20 05:09:38,355 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1216
2020-10-20 05:09:38,356 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:38,357 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:38,357 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:38,363 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1220
2020-10-20 05:09:38,363 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:51,924 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:09:51,924 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:09:51,927 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:09:53,776 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:09:53,819 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:09:53,907 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag ef5e1645a9374227a03c5c545269460e
2020-10-20 05:09:53,920 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:09:53,920 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:09:53,920 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:09:53,920 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:09:53,943 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:09:53,945 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:09:54,151 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:09:54,150 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:09:54,150 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:09:54,149 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:09:54,158 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4736
2020-10-20 05:09:54,158 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:54,158 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:54,159 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4737
2020-10-20 05:09:54,159 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:54,160 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:54,160 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:54,160 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4735
2020-10-20 05:09:54,160 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:54,160 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:54,160 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4734
2020-10-20 05:09:54,163 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:09:54,163 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:09:54,162 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:54,163 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:54,163 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:09:54,173 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 05:09:54,174 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:09:54,177 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:09:54,177 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:09:54,179 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:09:54,179 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:09:54,181 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 05:09:54,182 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:09:54,194 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:09:54,228 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:09:54,228 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:09:54,229 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:09:54,235 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:09:55,766 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1390
2020-10-20 05:09:55,767 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:55,789 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410
2020-10-20 05:09:55,789 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:55,841 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1462
2020-10-20 05:09:55,842 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:09:55,846 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1473
2020-10-20 05:09:55,846 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:10:11,638 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Invoking custom service failed.
2020-10-20 05:10:11,638 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 05:10:11,639 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 610
2020-10-20 05:10:11,639 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/service.py", line 100, in predict
2020-10-20 05:10:11,640 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     ret = self._entry_point(input_batch, self.context)
2020-10-20 05:10:11,640 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/ef5e1645a9374227a03c5c545269460e/FacenetHandler.py", line 91, in handle
2020-10-20 05:10:11,640 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     data = _service.postprocess(data)
2020-10-20 05:10:11,640 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/ef5e1645a9374227a03c5c545269460e/FacenetHandler.py", line 76, in postprocess
2020-10-20 05:10:11,640 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     if pred: output.append({ "dets" : [ list(coords.astype(str)) for coords in pred ]})
2020-10-20 05:10:11,641 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
2020-10-20 05:10:11,642 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 241051, Inference time ns: 614831404
2020-10-20 05:10:54,241 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:10:54,241 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:10:54,243 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:10:56,268 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:11:08,865 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:11:08,904 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:11:08,993 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 46367c27ab624528ba246f1d6aeee82a
2020-10-20 05:11:09,006 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:11:09,007 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:11:09,007 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:11:09,007 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:11:09,027 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:11:09,183 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:11:09,193 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:11:09,193 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:11:09,199 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4921
2020-10-20 05:11:09,199 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4920
2020-10-20 05:11:09,199 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:11:09,199 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4919
2020-10-20 05:11:09,200 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:11:09,200 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:11:09,200 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:11:09,200 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:11:09,206 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:11:09,206 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:11:09,212 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:11:09,212 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:11:09,212 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]4918
2020-10-20 05:11:09,212 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:11:09,213 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:11:09,213 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:11:09,213 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:11:09,214 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:11:09,214 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:11:09,214 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:11:09,215 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:11:09,283 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 05:11:09,283 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:11:09,286 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:11:09,288 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:11:09,288 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 05:11:09,289 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:11:09,292 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:11:09,295 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:11:09,300 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:11:10,613 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1226
2020-10-20 05:11:10,614 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:11:10,613 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234
2020-10-20 05:11:10,615 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:11:10,637 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250
2020-10-20 05:11:10,637 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:11:10,646 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278
2020-10-20 05:11:10,647 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:11:13,089 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 570
2020-10-20 05:11:13,091 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 240441, Backend time ns: 573758446
2020-10-20 05:11:16,891 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 568
2020-10-20 05:11:16,894 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 149711, Backend time ns: 573177064
2020-10-20 05:11:40,618 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Invoking custom service failed.
2020-10-20 05:11:40,618 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2
2020-10-20 05:11:40,618 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 05:11:40,619 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/service.py", line 100, in predict
2020-10-20 05:11:40,619 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     ret = self._entry_point(input_batch, self.context)
2020-10-20 05:11:40,619 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 89, in handle
2020-10-20 05:11:40,619 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     data = _service.preprocess(data)
2020-10-20 05:11:40,619 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 64, in preprocess
2020-10-20 05:11:40,619 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     images = [self.preprocess_one_image(req,i) for i,req in enumerate(reqs)]
2020-10-20 05:11:40,620 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 64, in <listcomp>
2020-10-20 05:11:40,620 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     images = [self.preprocess_one_image(req,i) for i,req in enumerate(reqs)]
2020-10-20 05:11:40,620 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 54, in preprocess_one_image
2020-10-20 05:11:40,620 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     response = requests.get(img_url)
2020-10-20 05:11:40,621 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/api.py", line 75, in get
2020-10-20 05:11:40,621 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return request('get', url, params=params, **kwargs)
2020-10-20 05:11:40,621 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/api.py", line 60, in request
2020-10-20 05:11:40,621 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return session.request(method=method, url=url, **kwargs)
2020-10-20 05:11:40,621 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/sessions.py", line 533, in request
2020-10-20 05:11:40,622 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     resp = self.send(prep, **send_kwargs)
2020-10-20 05:11:40,622 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/sessions.py", line 640, in send
2020-10-20 05:11:40,622 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     adapter = self.get_adapter(url=request.url)
2020-10-20 05:11:40,622 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/sessions.py", line 731, in get_adapter
2020-10-20 05:11:40,622 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise InvalidSchema("No connection adapters were found for '%s'" % url)
2020-10-20 05:11:40,623 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - requests.exceptions.InvalidSchema: No connection adapters were found for 'bytearray(b'https://datahunt.s3.ap-northeast-2.amazonaws.com/uploads/37/10016369_1565766485_image1_L.jpg')'
2020-10-20 05:11:40,639 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 149571, Inference time ns: 23616721
2020-10-20 05:11:42,934 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Invoking custom service failed.
2020-10-20 05:11:42,934 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3
2020-10-20 05:11:42,934 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Traceback (most recent call last):
2020-10-20 05:11:42,934 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ts/service.py", line 100, in predict
2020-10-20 05:11:42,935 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     ret = self._entry_point(input_batch, self.context)
2020-10-20 05:11:42,935 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 89, in handle
2020-10-20 05:11:42,935 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     data = _service.preprocess(data)
2020-10-20 05:11:42,935 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 64, in preprocess
2020-10-20 05:11:42,935 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 157361, Inference time ns: 5567704
2020-10-20 05:11:42,936 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     images = [self.preprocess_one_image(req,i) for i,req in enumerate(reqs)]
2020-10-20 05:11:42,936 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 64, in <listcomp>
2020-10-20 05:11:42,936 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     images = [self.preprocess_one_image(req,i) for i,req in enumerate(reqs)]
2020-10-20 05:11:42,937 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/tmp/models/46367c27ab624528ba246f1d6aeee82a/FacenetHandler.py", line 54, in preprocess_one_image
2020-10-20 05:11:42,937 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     response = requests.get(img_url)
2020-10-20 05:11:42,937 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/api.py", line 75, in get
2020-10-20 05:11:42,937 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return request('get', url, params=params, **kwargs)
2020-10-20 05:11:42,938 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/api.py", line 60, in request
2020-10-20 05:11:42,938 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     return session.request(method=method, url=url, **kwargs)
2020-10-20 05:11:42,938 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/sessions.py", line 533, in request
2020-10-20 05:11:42,938 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     resp = self.send(prep, **send_kwargs)
2020-10-20 05:11:42,938 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/sessions.py", line 640, in send
2020-10-20 05:11:42,939 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     adapter = self.get_adapter(url=request.url)
2020-10-20 05:11:42,939 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   File "/home/ubuntu/anaconda3/lib/python3.7/site-packages/requests/sessions.py", line 731, in get_adapter
2020-10-20 05:11:42,939 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     raise InvalidSchema("No connection adapters were found for '%s'" % url)
2020-10-20 05:11:42,939 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - requests.exceptions.InvalidSchema: No connection adapters were found for 'bytearray(b'https://datahunt.s3.ap-northeast-2.amazonaws.com/uploads/37/10016369_1565766485_image1_L.jpg')'
2020-10-20 05:12:12,889 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:12:12,889 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:12:12,891 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:12:14,909 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:12:17,686 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:12:17,725 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:12:17,815 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag b8c713c2baec4d97b030b97898063ae3
2020-10-20 05:12:17,829 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:12:17,830 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:12:17,830 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:12:17,830 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:12:17,849 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:12:17,976 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:12:18,000 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5103
2020-10-20 05:12:18,000 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:12:18,001 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:12:18,002 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:12:18,005 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:12:18,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5105
2020-10-20 05:12:18,010 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:12:18,011 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:12:18,010 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:12:18,015 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:12:18,018 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:12:18,019 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:12:18,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5102
2020-10-20 05:12:18,019 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:12:18,019 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:12:18,020 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:12:18,020 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:12:18,052 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:12:18,052 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5113
2020-10-20 05:12:18,053 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:12:18,053 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:12:18,053 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:12:18,053 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:12:18,118 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 05:12:18,118 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:12:18,128 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 05:12:18,128 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:12:18,128 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:12:18,130 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:12:18,131 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:12:18,133 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:12:18,135 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:12:19,437 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1212
2020-10-20 05:12:19,437 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234
2020-10-20 05:12:19,438 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245
2020-10-20 05:12:19,438 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:12:19,439 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:12:19,440 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:12:19,457 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232
2020-10-20 05:12:19,457 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:12:21,422 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 290
2020-10-20 05:12:21,425 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 208591, Backend time ns: 292924379
2020-10-20 05:12:23,246 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 231
2020-10-20 05:12:23,248 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 153551, Backend time ns: 233615003
2020-10-20 05:14:24,369 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 245
2020-10-20 05:14:24,371 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 131480, Backend time ns: 247162753
2020-10-20 05:16:37,465 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:16:37,466 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:16:37,465 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:16:39,486 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:16:42,638 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: http://127.0.0.1:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:16:42,678 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:16:42,770 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 6c5065a4d18e4805a0c548b7a98932ca
2020-10-20 05:16:42,784 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:16:42,784 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:16:42,784 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:16:42,785 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:16:42,803 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:16:42,947 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:16:42,949 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:16:42,952 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:16:42,953 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5300
2020-10-20 05:16:42,954 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:16:42,954 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:16:42,954 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5299
2020-10-20 05:16:42,954 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:16:42,954 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5301
2020-10-20 05:16:42,954 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:16:42,955 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:16:42,955 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:16:42,955 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:16:42,956 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:16:42,957 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:16:42,975 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:16:42,976 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:16:42,977 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:16:42,996 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:16:42,996 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5298
2020-10-20 05:16:42,997 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:16:42,997 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:16:42,997 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:16:42,998 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:16:43,072 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 05:16:43,074 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:16:43,079 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2020-10-20 05:16:43,079 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:16:43,079 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:16:43,079 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:16:43,089 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:16:43,089 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:16:43,094 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:16:44,382 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1207
2020-10-20 05:16:44,383 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:16:44,404 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252
2020-10-20 05:16:44,404 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:16:44,410 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255
2020-10-20 05:16:44,411 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:16:44,505 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1330
2020-10-20 05:16:44,505 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:16:46,423 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 228
2020-10-20 05:16:46,425 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 215231, Backend time ns: 231799306
2020-10-20 05:16:48,772 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 231
2020-10-20 05:16:48,775 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 127331, Backend time ns: 234538457
2020-10-20 05:17:51,707 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:17:51,707 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:17:51,708 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:17:53,721 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:18:46,736 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: logs/config/20201020021006917-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:18:46,742 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20201020021006917-shutdown.cfg",
  "modelCount": 0,
  "created": 1603159806917,
  "models": {}
}
2020-10-20 05:18:46,754 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20201020021006917-shutdown.cfg
2020-10-20 05:18:46,755 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20201020021006917-shutdown.cfg validated successfully
2020-10-20 05:18:46,756 [WARN ] main org.pytorch.serve.snapshot.SnapshotManager - Model snapshot is empty. Starting TorchServe without initial models.
2020-10-20 05:18:46,759 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:18:46,856 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 05:18:46,857 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:18:46,860 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2020-10-20 05:18:46,860 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:18:46,862 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:19:19,571 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:19:19,571 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:19:19,576 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:19:21,602 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:19:22,347 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: http://127.0.0.1:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:19:22,387 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:19:22,472 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 1ba3b990cc894d21997e3378ad69b6c9
2020-10-20 05:19:22,486 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:19:22,486 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:19:22,486 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:19:22,486 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:19:22,505 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:19:22,633 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:19:22,657 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:19:22,651 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:19:22,664 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5561
2020-10-20 05:19:22,664 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:19:22,664 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:19:22,665 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5560
2020-10-20 05:19:22,665 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:19:22,665 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:19:22,665 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5564
2020-10-20 05:19:22,665 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:19:22,666 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:19:22,666 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:19:22,667 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:19:22,667 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:19:22,669 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:19:22,671 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5559
2020-10-20 05:19:22,671 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:19:22,671 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:19:22,671 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:19:22,678 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:19:22,678 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:19:22,682 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:19:22,682 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:19:22,777 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2020-10-20 05:19:22,777 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:19:22,780 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2020-10-20 05:19:22,780 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:19:22,781 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:19:22,782 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:19:22,788 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:19:22,789 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:19:22,795 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:19:24,100 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254
2020-10-20 05:19:24,100 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:19:24,104 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260
2020-10-20 05:19:24,104 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:19:24,110 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235
2020-10-20 05:19:24,111 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:19:24,124 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247
2020-10-20 05:19:24,124 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:20:17,609 [INFO ] epollEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2020-10-20 05:20:17,609 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2020-10-20 05:20:17,611 [INFO ] epollEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2020-10-20 05:20:19,629 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2020-10-20 05:20:19,866 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.2.0
TS Home: /home/ubuntu/anaconda3/lib/python3.7/site-packages
Current directory: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve
Temp directory: /tmp
Number of GPUs: 0
Number of CPUs: 4
Max heap size: 7936 M
Python executable: /home/ubuntu/anaconda3/bin/python
Config file: config.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/ubuntu/work/InferenceModels/model_store
Initial Models: facenet.mar
Log dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Metrics dir: /home/ubuntu/work/InferenceModels/facenet-pytorch/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 4
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
2020-10-20 05:20:19,907 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: facenet.mar
2020-10-20 05:20:20,064 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 961c9a68ee14489e91eb1df1f42cb0eb
2020-10-20 05:20:20,113 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model facenet
2020-10-20 05:20:20,119 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model facenet
2020-10-20 05:20:20,120 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model facenet loaded.
2020-10-20 05:20:20,121 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: facenet, count: 4
2020-10-20 05:20:20,208 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2020-10-20 05:20:20,405 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9002
2020-10-20 05:20:20,408 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9000
2020-10-20 05:20:20,408 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5677
2020-10-20 05:20:20,409 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:20:20,409 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:20:20,410 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5678
2020-10-20 05:20:20,410 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:20:20,410 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:20:20,414 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:20:20,414 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:20:20,426 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9003
2020-10-20 05:20:20,426 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9002
2020-10-20 05:20:20,428 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5680
2020-10-20 05:20:20,427 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2020-10-20 05:20:20,435 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:20:20,436 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:20:20,436 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9003
2020-10-20 05:20:20,436 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:20:20,439 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /tmp/.ts.sock.9001
2020-10-20 05:20:20,440 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]5679
2020-10-20 05:20:20,440 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.
2020-10-20 05:20:20,440 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.7.6
2020-10-20 05:20:20,440 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change null -> WORKER_STARTED
2020-10-20 05:20:20,441 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9001
2020-10-20 05:20:20,520 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2020-10-20 05:20:20,520 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2020-10-20 05:20:20,524 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2020-10-20 05:20:20,525 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2020-10-20 05:20:20,528 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2020-10-20 05:20:20,539 [INFO ] W-9000-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9000.
2020-10-20 05:20:20,539 [INFO ] W-9002-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9002.
2020-10-20 05:20:20,539 [INFO ] W-9001-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9001.
2020-10-20 05:20:20,541 [INFO ] W-9003-facenet_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /tmp/.ts.sock.9003.
2020-10-20 05:20:21,861 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230
2020-10-20 05:20:21,861 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253
2020-10-20 05:20:21,861 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:20:21,861 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:20:21,864 [INFO ] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253
2020-10-20 05:20:21,864 [DEBUG] W-9002-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:20:21,868 [INFO ] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236
2020-10-20 05:20:21,868 [DEBUG] W-9001-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-facenet_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2020-10-20 05:20:34,365 [INFO ] W-9000-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 253
2020-10-20 05:20:34,369 [DEBUG] W-9000-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 209651, Backend time ns: 257953177
2020-10-20 05:22:11,709 [INFO ] W-9003-facenet_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 232
2020-10-20 05:22:11,713 [DEBUG] W-9003-facenet_1.0 org.pytorch.serve.wlm.Job - Waiting time ns: 154581, Backend time ns: 236844475
